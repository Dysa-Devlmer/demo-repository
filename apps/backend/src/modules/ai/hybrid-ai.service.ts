import { Injectable, Logger } from '@nestjs/common';
import { ConfigService } from '@nestjs/config';
import { OllamaService, RestaurantContext } from './ollama.service';
import OpenAI from 'openai';

export interface AIResponse {
  content: string;
  provider: 'openai' | 'ollama' | 'fallback';
  tokensUsed?: number;
  responseTime: number;
  cached?: boolean;
}

export interface ConversationMessage {
  role: 'system' | 'user' | 'assistant';
  content: string;
  timestamp?: Date;
}

@Injectable()
export class HybridAIService {
  private readonly logger = new Logger(HybridAIService.name);
  private openai: OpenAI | null = null;
  private readonly useOpenAI: boolean;
  private readonly openaiModel: string = 'gpt-4o-mini';

  // Cache de respuestas para preguntas frecuentes
  private responseCache = new Map<string, { response: string; timestamp: number }>();
  private readonly cacheExpiration = 3600000; // 1 hora

  constructor(
    private readonly configService: ConfigService,
    private readonly ollamaService: OllamaService,
  ) {
    const openaiKey = this.configService.get<string>('OPENAI_API_KEY');

    if (openaiKey && openaiKey.trim().length > 0) {
      this.openai = new OpenAI({
        apiKey: openaiKey,
      });
      this.useOpenAI = true;
      this.logger.log('‚úÖ HybridAI initialized with OpenAI GPT-4o-mini (primary) + Ollama (fallback)');
    } else {
      this.useOpenAI = false;
      this.logger.warn('‚ö†Ô∏è  OpenAI not configured, using Ollama only');
    }
  }

  /**
   * Genera una respuesta inteligente usando el mejor proveedor disponible
   */
  async generateResponse(
    userMessage: string,
    context: RestaurantContext,
  ): Promise<AIResponse> {
    const startTime = Date.now();

    // 1. Verificar cache para preguntas frecuentes
    const cacheKey = this.getCacheKey(userMessage, context);
    const cached = this.getFromCache(cacheKey);
    if (cached) {
      this.logger.debug('üì¶ Response from cache');
      return {
        content: cached,
        provider: 'openai',
        responseTime: Date.now() - startTime,
        cached: true,
      };
    }

    // 2. Construir el prompt con RESTRICCIONES ESTRICTAS
    const systemPrompt = this.buildRestrictedSystemPrompt(context);
    const messages = this.buildMessages(systemPrompt, userMessage, context);

    // 3. Intentar OpenAI primero (m√°s natural)
    if (this.useOpenAI && this.openai) {
      try {
        const response = await this.generateWithOpenAI(messages);

        // Guardar en cache si es exitoso
        this.saveToCache(cacheKey, response.content);

        return {
          ...response,
          responseTime: Date.now() - startTime,
        };
      } catch (error) {
        this.logger.warn('OpenAI failed, falling back to Ollama:', error instanceof Error ? error.message : 'Unknown error');
      }
    }

    // 4. Fallback a Ollama
    try {
      const content = await this.ollamaService.generateRestaurantResponse(
        userMessage,
        context,
      );

      return {
        content,
        provider: 'ollama',
        responseTime: Date.now() - startTime,
      };
    } catch (error) {
      this.logger.error('Both AI providers failed, using fallback:', error instanceof Error ? error.message : 'Unknown error');

      // 5. Fallback final: respuestas pre-programadas
      return {
        content: this.getFallbackResponse(userMessage, context),
        provider: 'fallback',
        responseTime: Date.now() - startTime,
      };
    }
  }

  /**
   * Construye un prompt con restricciones ESTRICTAS para que solo hable del restaurante
   */
  private buildRestrictedSystemPrompt(context: RestaurantContext): string {
    const restaurantName = context.restaurantInfo?.name || 'nuestro restaurante';

    return `Eres ChefBot Dysa üë®‚Äçüç≥, el asistente virtual EXCLUSIVO de ${restaurantName}.

üö´ RESTRICCIONES ABSOLUTAS:
1. SOLO puedes hablar sobre ${restaurantName}: men√∫, reservas, pedidos, horarios, ubicaci√≥n, especialidades
2. NO tienes acceso a internet ni informaci√≥n externa
3. NO respondas preguntas sobre otros restaurantes, noticias, clima, deportes, etc.
4. SI te preguntan algo fuera del restaurante, responde: "Lo siento, solo puedo ayudarte con informaci√≥n sobre ${restaurantName}. ¬øTe gustar√≠a conocer nuestro men√∫, hacer una reserva o realizar un pedido?"

‚úÖ PUEDES AYUDAR CON:
- üçΩÔ∏è Consultar men√∫, precios, ingredientes, platos del d√≠a
- üìÖ Hacer, modificar o cancelar reservas
- üõµ Tomar pedidos para delivery o takeaway
- ‚ÑπÔ∏è Informaci√≥n del restaurante (horarios, ubicaci√≥n, tel√©fono)
- üéÅ Promociones y especialidades actuales
- ‚ùì Preguntas sobre m√©todos de pago, pol√≠ticas de cancelaci√≥n

üìã INFORMACI√ìN DEL RESTAURANTE:
${context.restaurantInfo ? `
- Nombre: ${context.restaurantInfo.name}
- Direcci√≥n: ${context.restaurantInfo.address || 'Consultar'}
- Tel√©fono: ${context.restaurantInfo.phone || 'Consultar'}
- Horarios: ${context.restaurantInfo.hours || 'Consultar'}
- Especialidades: ${context.restaurantInfo.specialties?.join(', ') || 'Consultar men√∫'}
` : 'Informaci√≥n no disponible'}

${context.menuItems && context.menuItems.length > 0 ? `
üçΩÔ∏è MEN√ö DISPONIBLE (${context.menuItems.length} items):
${context.menuItems.map(item =>
  `- ${item.name}: $${item.price} - ${item.description || item.category}${item.available === false ? ' (No disponible)' : ''}`
).join('\n')}
` : ''}

üë§ CONTEXTO DEL CLIENTE:
${context.customerName ? `Nombre: ${context.customerName}` : 'Cliente nuevo'}
${context.reservations && context.reservations.length > 0 ? `
Reservas activas: ${context.reservations.length}
${context.reservations.map(r =>
  `- ${r.reservation_code}: ${r.reservation_date} para ${r.party_size} personas (${r.status})`
).join('\n')}
` : ''}

üéØ ESTILO DE RESPUESTA:
- Natural, c√°lido y profesional (como un mesero experto)
- Usa emojis apropiados pero sin exagerar
- Respuestas concisas (2-3 oraciones m√°ximo)
- Si no sabes algo del restaurante, s√© honesto y ofrece contactar al personal
- Termina con una pregunta amigable para continuar la conversaci√≥n
- NUNCA inventes informaci√≥n que no tengas

üö´ LO QUE NUNCA DEBES HACER:
- Hablar de temas fuera del restaurante
- Inventar platos o precios que no est√°n en el men√∫
- Dar informaci√≥n sobre otros restaurantes
- Responder preguntas generales de internet
- Hacer recomendaciones basadas en informaci√≥n externa

RECUERDA: Eres el asistente del restaurante, no un asistente general de IA.`;
  }

  /**
   * Construye los mensajes para la conversaci√≥n
   */
  private buildMessages(
    systemPrompt: string,
    userMessage: string,
    context: RestaurantContext,
  ): ConversationMessage[] {
    const messages: ConversationMessage[] = [
      { role: 'system', content: systemPrompt },
    ];

    // Agregar mensajes previos (m√°ximo 10 para no exceder contexto)
    if (context.previousMessages && context.previousMessages.length > 0) {
      const recentMessages = context.previousMessages.slice(-10);
      messages.push(...recentMessages.map(msg => ({
        role: msg.role,
        content: msg.content,
        timestamp: new Date(),
      })));
    }

    // Agregar mensaje actual
    messages.push({
      role: 'user',
      content: userMessage,
      timestamp: new Date(),
    });

    return messages;
  }

  /**
   * Genera respuesta con OpenAI GPT-4o-mini
   */
  private async generateWithOpenAI(
    messages: ConversationMessage[],
  ): Promise<Omit<AIResponse, 'responseTime'>> {
    if (!this.openai) {
      throw new Error('OpenAI not initialized');
    }

    try {
      const completion = await this.openai.chat.completions.create({
        model: this.openaiModel,
        messages: messages.map(m => ({
          role: m.role,
          content: m.content,
        })),
        temperature: 0.7, // Natural pero consistente
        max_tokens: 200, // Respuestas concisas
        presence_penalty: 0.6, // Evita repetici√≥n
        frequency_penalty: 0.3, // M√°s variedad en palabras
      });

      const content = completion.choices[0]?.message?.content || '';
      const tokensUsed = completion.usage?.total_tokens || 0;

      this.logger.debug(`OpenAI response: ${tokensUsed} tokens`);

      return {
        content,
        provider: 'openai',
        tokensUsed,
      };
    } catch (error) {
      if (error instanceof Error) {
        this.logger.error('OpenAI API error:', error.message);
      }
      throw error;
    }
  }

  /**
   * Obtiene una respuesta de fallback pre-programada
   */
  private getFallbackResponse(
    userMessage: string,
    context: RestaurantContext,
  ): string {
    const lowerMessage = userMessage.toLowerCase();
    const restaurantName = context.restaurantInfo?.name || 'nuestro restaurante';

    // Respuestas comunes pre-programadas
    if (lowerMessage.includes('hola') || lowerMessage.includes('buenos') || lowerMessage.includes('buenas')) {
      return `¬°Hola! üëã Bienvenido a ${restaurantName}. ¬øTe gustar√≠a conocer nuestro men√∫, hacer una reserva o realizar un pedido?`;
    }

    if (lowerMessage.includes('men√∫') || lowerMessage.includes('menu') || lowerMessage.includes('platos')) {
      if (context.menuItems && context.menuItems.length > 0) {
        return `Te muestro nuestro men√∫:\n\n${context.menuItems.slice(0, 5).map(item => `üçΩÔ∏è ${item.name} - $${item.price}`).join('\n')}\n\n¬øTe gustar√≠a saber m√°s sobre alg√∫n plato?`;
      }
      return `Tenemos un men√∫ delicioso. ¬øQu√© tipo de comida te gustar√≠a? üçΩÔ∏è`;
    }

    if (lowerMessage.includes('reserva')) {
      return `Con gusto te ayudo con tu reserva üìÖ. ¬øPara cu√°ntas personas y qu√© d√≠a te gustar√≠a reservar?`;
    }

    if (lowerMessage.includes('pedido') || lowerMessage.includes('delivery') || lowerMessage.includes('ordenar')) {
      return `¬°Perfecto! üõµ ¬øQu√© te gustar√≠a ordenar? Puedo ayudarte a armar tu pedido del men√∫.`;
    }

    if (lowerMessage.includes('horario') || lowerMessage.includes('hora')) {
      const hours = context.restaurantInfo?.hours || 'Lunes a Domingo de 12:00 a 23:00';
      return `Nuestros horarios son: ${hours} ‚è∞`;
    }

    if (lowerMessage.includes('direcci√≥n') || lowerMessage.includes('direccion') || lowerMessage.includes('ubicaci√≥n') || lowerMessage.includes('ubicacion') || lowerMessage.includes('donde')) {
      const address = context.restaurantInfo?.address || 'Consulta con nosotros';
      return `Estamos ubicados en: ${address} üìç`;
    }

    // Respuesta gen√©rica
    return `Disculpa, en este momento tengo dificultades t√©cnicas para responderte. üòÖ Pero puedo ayudarte con:\n\nüçΩÔ∏è Consultar el men√∫\nüìÖ Hacer reservas\nüõµ Tomar pedidos\nüìû Informaci√≥n del restaurante\n\n¬øCon qu√© te gustar√≠a ayuda?`;
  }

  /**
   * Sistema de cach√© para respuestas frecuentes
   */
  private getCacheKey(message: string, context: RestaurantContext): string {
    const normalized = message.toLowerCase().trim();
    const restaurantId = context.restaurantInfo?.name || 'default';
    return `${restaurantId}:${normalized}`;
  }

  private getFromCache(key: string): string | null {
    const cached = this.responseCache.get(key);
    if (!cached) return null;

    const isExpired = Date.now() - cached.timestamp > this.cacheExpiration;
    if (isExpired) {
      this.responseCache.delete(key);
      return null;
    }

    return cached.response;
  }

  private saveToCache(key: string, response: string): void {
    // Limpiar cache si es muy grande (m√°ximo 100 entradas)
    if (this.responseCache.size > 100) {
      const firstKey = this.responseCache.keys().next().value;
      if (firstKey) {
        this.responseCache.delete(firstKey);
      }
    }

    this.responseCache.set(key, {
      response,
      timestamp: Date.now(),
    });
  }

  /**
   * Limpia el cach√© (√∫til para testing o reinicio)
   */
  clearCache(): void {
    this.responseCache.clear();
    this.logger.log('Cache cleared');
  }

  /**
   * Obtiene estad√≠sticas del servicio
   */
  getStats() {
    return {
      service: 'Hybrid AI Service',
      primaryProvider: this.useOpenAI ? 'OpenAI GPT-4o-mini' : 'Ollama only',
      fallbackProvider: 'Ollama',
      emergencyFallback: 'Pre-programmed responses',
      cacheSize: this.responseCache.size,
      cacheExpiration: `${this.cacheExpiration / 60000} minutes`,
      openaiConfigured: this.useOpenAI,
      model: this.openaiModel,
    };
  }

  /**
   * Health check
   */
  async healthCheck(): Promise<{
    openai: boolean;
    ollama: boolean;
    overall: boolean;
  }> {
    const openaiHealthy = this.openai !== null;
    const ollamaHealthy = await this.ollamaService.isOllamaRunning();

    return {
      openai: openaiHealthy,
      ollama: ollamaHealthy,
      overall: openaiHealthy || ollamaHealthy,
    };
  }
}
